{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense,Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, ElasticNet\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev : 10/298\n",
      "Dev : 20/298\n",
      "Dev : 30/298\n",
      "Dev : 40/298\n",
      "Dev : 50/298\n",
      "Dev : 60/298\n",
      "Dev : 70/298\n",
      "Dev : 80/298\n",
      "Dev : 90/298\n",
      "Dev : 100/298\n",
      "Dev : 110/298\n",
      "Dev : 120/298\n",
      "Dev : 130/298\n",
      "Dev : 140/298\n",
      "Dev : 150/298\n",
      "Dev : 160/298\n",
      "Dev : 170/298\n",
      "Dev : 180/298\n",
      "Dev : 190/298\n",
      "Dev : 200/298\n",
      "Dev : 210/298\n",
      "Dev : 220/298\n",
      "Dev : 230/298\n",
      "Dev : 240/298\n",
      "Dev : 250/298\n",
      "Dev : 260/298\n",
      "Dev : 270/298\n",
      "Dev : 280/298\n",
      "Dev : 290/298\n"
     ]
    }
   ],
   "source": [
    "FILEROOT = \"audio/\"\n",
    "labels = {'beach': 0,\n",
    "          'bus': 1,\n",
    "          'cafe/restaurant': 2,\n",
    "          'car': 3,\n",
    "          'city_center': 4,\n",
    "          'forest_path': 5,\n",
    "          'grocery_store': 6,\n",
    "          'home': 7,\n",
    "          'library': 8,\n",
    "          'metro_station': 9,\n",
    "          'office': 10,\n",
    "          'park': 11,\n",
    "          'residential_area': 12,\n",
    "          'train': 13,\n",
    "          'tram' : 14\n",
    "          }\n",
    "dev_files = pd.read_table(os.path.join(FILEROOT, \"dev.txt\"), names=['file', 'label'], sep='\\s+')\n",
    "\n",
    "for i, afile in dev_files.iterrows():\n",
    "    y, sr = librosa.load(str(afile.file), sr=None)\n",
    "    stft = np.abs(librosa.stft(y))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y, sr=sr).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sr).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr).T,axis=0)\n",
    "    \n",
    "    line = np.concatenate([mfccs, chroma, mel, contrast, tonnetz]) \n",
    "    \n",
    "    if i == 0:\n",
    "        X_dev = [line]\n",
    "        y_dev = [labels[afile.label]]\n",
    "    else:\n",
    "        X_dev += [line]\n",
    "        y_dev += [labels[afile.label]]\n",
    "    if ((i+1) % 10 == 0 or i+1 == test_files.shape[0]):\n",
    "        print(\"Dev : {0}/{1}\".format(i+1, test_files.shape[0]))\n",
    "np.save(\"X_dev\", X_dev)\n",
    "np.save(\"y_dev\", y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 10/582\n",
      "Train : 20/582\n",
      "Train : 30/582\n",
      "Train : 40/582\n",
      "Train : 50/582\n",
      "Train : 60/582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexisr\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\librosa\\core\\pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 70/582\n",
      "Train : 80/582\n",
      "Train : 90/582\n",
      "Train : 100/582\n",
      "Train : 110/582\n",
      "Train : 120/582\n",
      "Train : 130/582\n",
      "Train : 140/582\n",
      "Train : 150/582\n",
      "Train : 160/582\n",
      "Train : 170/582\n",
      "Train : 180/582\n",
      "Train : 190/582\n",
      "Train : 200/582\n",
      "Train : 210/582\n",
      "Train : 220/582\n",
      "Train : 230/582\n",
      "Train : 240/582\n",
      "Train : 250/582\n",
      "Train : 260/582\n",
      "Train : 270/582\n",
      "Train : 280/582\n",
      "Train : 290/582\n",
      "Train : 300/582\n",
      "Train : 310/582\n",
      "Train : 320/582\n",
      "Train : 330/582\n",
      "Train : 340/582\n",
      "Train : 350/582\n",
      "Train : 360/582\n",
      "Train : 370/582\n",
      "Train : 380/582\n",
      "Train : 390/582\n",
      "Train : 400/582\n",
      "Train : 410/582\n",
      "Train : 420/582\n",
      "Train : 430/582\n",
      "Train : 440/582\n",
      "Train : 450/582\n",
      "Train : 460/582\n",
      "Train : 470/582\n",
      "Train : 480/582\n",
      "Train : 490/582\n",
      "Train : 500/582\n",
      "Train : 510/582\n",
      "Train : 520/582\n",
      "Train : 530/582\n",
      "Train : 540/582\n",
      "Train : 550/582\n",
      "Train : 560/582\n",
      "Train : 570/582\n",
      "Train : 580/582\n",
      "Train : 582/582\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9b86cbc0f6d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[0mX_tot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[0mX_tot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_tot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "FILEROOT = \"audio/\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "train_files = pd.read_table(os.path.join(FILEROOT, \"train.txt\"), names=['file', 'label'], sep='\\s+')\n",
    "test_files = pd.read_table(os.path.join(FILEROOT, \"test_files.txt\"), names=['file', 'label'], sep='\\s+')\n",
    "\n",
    "labels = {'beach': 0,\n",
    "          'bus': 1,\n",
    "          'cafe/restaurant': 2,\n",
    "          'car': 3,\n",
    "          'city_center': 4,\n",
    "          'forest_path': 5,\n",
    "          'grocery_store': 6,\n",
    "          'home': 7,\n",
    "          'library': 8,\n",
    "          'metro_station': 9,\n",
    "          'office': 10,\n",
    "          'park': 11,\n",
    "          'residential_area': 12,\n",
    "          'train': 13,\n",
    "          'tram' : 14\n",
    "          }\n",
    "\n",
    "for i, afile in train_files.iterrows():\n",
    "\n",
    "    y, sr = librosa.load(str(afile.file), sr=None)\n",
    "    \n",
    "    stft = np.abs(librosa.stft(y))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y, sr=sr).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sr).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr).T,axis=0)\n",
    "    \n",
    "    line = np.concatenate([mfccs, chroma, mel, contrast, tonnetz])    \n",
    "    \n",
    "    if i == 0:\n",
    "        X_train = [line]\n",
    "        y_train = [labels[afile.label]]\n",
    "    else:\n",
    "        X_train += [line]\n",
    "        y_train += [labels[afile.label]]\n",
    "    if ((i+1) % 10 == 0 or i+1 == train_files.shape[0]):\n",
    "        print(\"Train : {0}/{1}\".format(i+1, train_files.shape[0]))\n",
    "\n",
    "\"\"\"for i, afile in test_files.iterrows():\n",
    "\n",
    "    y, sr = librosa.load(str(afile.file), sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, n_fft=512, hop_length=512, n_mfcc=40)\n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    # librosa.display.specshow(librosa.power_to_db(np.abs(mfcc), ref=np.max),\n",
    "    #                         y_axis='mel', x_axis='time')\n",
    "    mfcc = np.mean(mfcc, axis=1)\n",
    "    if i == 0:\n",
    "        X_test = [mfcc]\n",
    "    else:\n",
    "        X_test += [mfcc]\n",
    "    if ((i+1) % 100 == 0 or i+1 == test_files.shape[0]):\n",
    "        print(\"Test : {0}/{1}\".format(i+1, test_files.shape[0]))\"\"\"\n",
    "\n",
    "\n",
    "X_tot = np.concatenate([X_train, X_test])\n",
    "X_tot = preprocessing.scale(X_tot)\n",
    "X_train = X_tot[:len(X_train)]\n",
    "X_test = X_tot[len(X_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cf2b913b63f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y_pred.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "print(cross_val_score(clf,X_train,y_train,cv=5))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "np.savetxt(\"y_pred.txt\", y_pred, fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_trainonehot = pd.get_dummies(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
